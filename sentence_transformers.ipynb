{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCMea1tUqj0h3usMQ593Fh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaycode/machine-learning/blob/main/sentence_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np_UF1hSzjvW",
        "outputId": "7d7d4c0b-e3ac-49c4-8032-9dd1b368185a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences sorted by similarity:\n",
            "\n",
            "tensor([0.8527]) I hot patched the issue.\n",
            "tensor([0.7057]) Verified. The issue exists.I fixed this by a pull request.\n",
            "tensor([0.6800]) Refactored the code to resolve the issue.\n",
            "tensor([0.6678]) I turned on the heater.\n",
            "tensor([0.5144]) Race-condition identified and submitted a pull request.\n",
            "tensor([0.5081]) The developer patched the dry-wall.\n",
            "tensor([0.4464]) Invalid. The code works on my machine.\n",
            "tensor([0.4329]) Capacity issue. Fixed by adding more clusters in the region.\n",
            "tensor([0.4024]) This was not a bug, must be a False Postive.\n",
            "tensor([0.3259]) Transient issue.\n",
            "tensor([0.2517]) This was not a bug.\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, LoggingHandler, util\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "intent = 'I fixed the issue with a hot-patch'\n",
        "other_sentences = ['This was not a bug.',\n",
        "          'Refactored the code to resolve the issue.',\n",
        "          'Invalid. The code works on my machine.',\n",
        "          'Race-condition identified and submitted a pull request.',\n",
        "          'This was not a bug, must be a False Postive.',\n",
        "          'Capacity issue. Fixed by adding more clusters in the region.',\n",
        "          'Transient issue.',\n",
        "          'Verified. The issue exists.'\n",
        "          'I fixed this by a pull request.',\n",
        "          'I hot patched the issue.',\n",
        "          'I turned on the heater.',\n",
        "          'The developer patched the dry-wall.'\n",
        "          ]\n",
        "\n",
        "#Encode all sentences\n",
        "intent_embedding = model.encode (intent)\n",
        "embeddings = model.encode(other_sentences)\n",
        "\n",
        "#Compute cosine similarity between all pairs\n",
        "cos_sim = util.cos_sim( embeddings,intent_embedding)\n",
        "\n",
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations = []\n",
        "\n",
        "for i in range(len(cos_sim)):\n",
        "    all_sentence_combinations.append([cos_sim[i], i])\n",
        "\n",
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "print(\"Sentences sorted by similarity:\\n\")\n",
        "for score, i in all_sentence_combinations:\n",
        "    print (cos_sim[i], other_sentences[i])\n"
      ]
    }
  ]
}